# Productivity
## Directory Structure
```
├─GPT_DATA: contains codes for experiments.
|
├─HF_Augmented_Data: contains all of the experimental results.
|
├─visualization: contains visualization files for results.
```


## Explanation about Python Codes
```arc_example_generator.py```: augments example inputs with GPT.

```ITP_generator.py```: generates prompts for Inverse Transformation Prompting (ITP).


## Quick Start
```
cd Productivity
python making_prompt.py
python gpt_3.5_arc_example_generator.py
python gpt_4.0_arc_example_generator.py
```

## What is Productivity?
**Productivity refers to the ability to generate unseen representations based on observed data.** 
This characteristic allows humans to imagine different situations even from a single phenomenon, thus allowing for efficient learning without the need to learn from data inefficiently each time. 
Similarly, when equipped with this ability, LLMs are expected to excel in unseen tasks, making it one of the key functions of essential reasoning. 
The ability to generate new pairs within a limited set of rules could be helpful while solving ARC tasks, highlighting the need for productivity.


## How to Experiment to Evaluate the Productivity of LLM?
We conduct experiments using ARC tasks to understand how well LLM can generate new expressions based on inherent logical concepts. 
Productivity involves two main steps: 1) inferring specific rules for generating images from example images and natural language expressions and 2) using those rules to generate new, unseen images. 
However, solving ARC tasks, experimented on in the previous sections so far, is unsuitable for confirming these two processes.
For precise evaluation, we propose a new experiment: _Given an ARC task and a basic rule shared with similar ARC tasks, can LLM generate valid examples of the given task?_ 
If LLM can understand a relationship between the given ARC task and the abstract rule, they should be able to infer specific rules for the given task and generate new valid examples. 
The abstract rules were written according to categories from [ConceptARC](https://github.com/victorvikram/ConceptARC).
Through this, we want to see if LLM can imitate human thinking productivity.

![overall_process_productivity_page-0001](https://github.com/GIST-DSLab/ARC_Prompt/assets/22788924/d4cefef0-b6df-4141-8751-6893ebf8bea4)

For this experiment, we create Inverse Transformation Prompting (ITP) to augment example inputs for the given output of each ARC task.
First, the given ARC task (*Above Below*) is located on the left side of the above figure.
The task contains three example pairs and we generate ITP with only two examples.
The experimental goal is to generate valid examples of the given task by augmenting inputs paired with the output of the last example.
Therefore, in this experiment, we give the ITP and the output of the last example to LLM (GPT-3.5 or GPT-4) and measure the validity of inputs generated by LLM.


## Results
|Problem Category|Total available|The number of generated data|The number of valid augmentated data|Ratio(valid/generated)|
|:---:|:---:|:---:|:---:|:---:|
|[Above Below](https://github.com/GIST-DSLab/Augmentation_with_GPT/blob/main/visualization/AboveBelow.pdf)|58|158|34|21.52%|
|[Center](https://github.com/GIST-DSLab/Augmentation_with_GPT/blob/main/visualization/Center.pdf)|65|236|35|14.83%|
|[Clean Up](https://github.com/GIST-DSLab/Augmentation_with_GPT/blob/main/visualization/CleanUp.pdf)|106|183|83|45.36%|
|[Complete Shape](https://github.com/GIST-DSLab/Augmentation_with_GPT/blob/main/visualization/CompleteShape.pdf)|58|147|37|25.17%|
|[Copy](https://github.com/GIST-DSLab/Augmentation_with_GPT/blob/main/visualization/Copy.pdf)|27|153|4|2.61%|
|[Count](https://github.com/GIST-DSLab/Augmentation_with_GPT/blob/main/visualization/Count.pdf)|56|202|29|14.36%|
|[Extend To Boundary](https://github.com/GIST-DSLab/Augmentation_with_GPT/blob/main/visualization/ExtendToBoundary.pdf)|37|167|8|4.79%|
|[Extract Objects](https://github.com/GIST-DSLab/Augmentation_with_GPT/blob/main/visualization/ExtractObjects.pdf)|44|176|21|11.93%|
|[Filled Not Filled](https://github.com/GIST-DSLab/Augmentation_with_GPT/blob/main/visualization/FilledNotFilled.pdf)|58|203|29|14.29%|
|[Horizontal Vertical](https://github.com/GIST-DSLab/Augmentation_with_GPT/blob/main/visualization/HorizontalVertical.pdf)|32|114|7|6.14%|
|[Inside Outside](https://github.com/GIST-DSLab/Augmentation_with_GPT/blob/main/visualization/InsideOutside.pdf)|52|191|24|12.57%|
|[Move To  Boundary](https://github.com/GIST-DSLab/Augmentation_with_GPT/blob/main/visualization/MoveToBoundary.pdf)|36|165|12|7.27%|
|[Order](https://github.com/GIST-DSLab/Augmentation_with_GPT/blob/main/visualization/Order.pdf)|47|162|26|16.05%|
|[Same Different](https://github.com/GIST-DSLab/Augmentation_with_GPT/blob/main/visualization/SameDifferent.pdf)|107|246|76|30.89%|
|[Top Bottom 2D](https://github.com/GIST-DSLab/Augmentation_with_GPT/blob/main/visualization/TopBottom2D.pdf)|92|255|59|23.14%|
|[Top Bottom 3D](https://github.com/GIST-DSLab/Augmentation_with_GPT/blob/main/visualization/TopBottom3D.pdf)|55|215|25|11.63%|
|Total|930|2913|509|17.12%|


## Etc
We modify [tanchongmin's code](https://github.com/tanchongmin/ARC-Challenge) to make the visualization code and use it to visualize the ARC grid. 
